# Secure Machine Learning Experiments

This is a collection of miscellaneous notebooks demonstrating concepts and tools in machine learning security. 

## Overview 

+ `AdverTorch.ipynb` - Launches two PGD attacks against MobileNet using the AdverTorch framework
+ `Foolbox.ipynb` - Launches the FGSM and Boundary attacks against MobileNet using the Foolbox framework
+ `KnockoffNet.ipynb` - Implements a Knockoff Nets model extraction attack against an MNIST model 
+ `Tramer.ipynb` - Implements Tramer's uniform noise model extraction attack against an MNIST model 

## External Resources 

This is still under construction. 

+ [Nicholas Carlini's Adversarial Machine Learning Reading List](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html)
+ [Microsoft Failure Modes in Machine Learning](https://docs.microsoft.com/en-us/security/engineering/failure-modes-in-machine-learning)
+ [TensorFlow Cleverhans](https://github.com/tensorflow/cleverhans)
+ [IBM Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox)

## Contact

If you're interested in discussing machine learning security further, feel free to contact me at `suhashussain1 'at' gmail.com`.
